{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianaleticiamartinez/mcd_deep_learning/blob/main/GeneradorDeCuentos_AdrianaMartinez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Generador de Cuentos Infantiles con LSTM\n",
        "### Adriana Leticia Martinez\n",
        "### Universidad Panamericana\n",
        "\n",
        "Este notebook contiene la implementación de un modelo LSTM para la generación de cuentos infantiles. El modelo fue entrenado utilizando distintos números de épocas (1,10, 60, 150 y 180), y se incluye la posibilidad de probar diferentes modelos entrenados. Los datos de entrenamiento y los caracteres necesarios para realizar la predicción son importados desde archivos externos.\n",
        "\n",
        "## Módulos del Código\n",
        "\n",
        "### 1. **Importación de Modelos y Datos**\n",
        "El código incluye un bloque para descargar los modelos entrenados y los archivos de caracteres necesarios desde una URL pública. Estos modelos incluyen versiones entrenadas con diferentes épocas\n",
        "\n",
        "```python\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_60epoch.pth\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/chars/chars60.pkl\n",
        "```\n",
        "\n",
        "### 2. **Clase LSTM**\n",
        "La clase `LSTM` define la arquitectura del modelo de red neuronal recurrente. Utiliza múltiples capas de LSTM y una capa completamente conectada para la predicción de caracteres.\n",
        "\n",
        "- **Parámetros**:\n",
        "  - `chars`: El conjunto de caracteres utilizados durante el entrenamiento y predicción.\n",
        "  - `n_hidden`: Número de unidades en las capas ocultas.\n",
        "  - `n_layers`: Número de capas LSTM.\n",
        "  - `drop_prob`: Tasa de *dropout* para evitar sobreajuste.\n",
        "\n",
        "\n",
        "### 3. **Función `one_hot_encode`**\n",
        "Esta función toma un arreglo de índices de caracteres y los convierte en una representación *one-hot* para ser utilizada como entrada al modelo.\n",
        "\n",
        "```python\n",
        "def one_hot_encode(arr, n_labels):\n",
        "    # Codifica el arreglo de índices en formato one-hot\n",
        "```\n",
        "\n",
        "### 4. **Función `predict`**\n",
        "La función `predict` predice el siguiente carácter utilizando el modelo entrenado. Utiliza la salida de la red LSTM para aplicar una función *softmax* y obtener las probabilidades de los caracteres siguientes más probables.\n",
        "\n",
        "- **Parámetros**:\n",
        "  - `model`: El modelo LSTM entrenado.\n",
        "  - `char`: El carácter actual utilizado para generar la predicción.\n",
        "  - `device`: El dispositivo (CPU o GPU) en el que se ejecuta el modelo.\n",
        "  - `h`: El estado oculto del modelo.\n",
        "\n",
        "```python\n",
        "def predict(model, char, device, h=None, top_k=5):\n",
        "    # Predice el siguiente carácter en la secuencia\n",
        "```\n",
        "\n",
        "### 5. **Función `sample`**\n",
        "La función `sample` es la encargada de generar una secuencia de texto a partir de un modelo entrenado y una secuencia inicial (`prime`). Va generando caracteres de manera recurrente basándose en la predicción del carácter más probable.\n",
        "\n",
        "- **Parámetros**:\n",
        "  - `model`: El modelo LSTM cargado.\n",
        "  - `size`: La cantidad de caracteres que se desea generar.\n",
        "  - `prime`: La secuencia inicial con la que se inicia la generación de texto.\n",
        "  - `top_k`: Número de caracteres más probables a considerar en cada predicción.\n",
        "\n",
        "```python\n",
        "def sample(model, size, prime='Once upon a time,', top_k=5):\n",
        "    # Genera una secuencia de texto a partir del modelo entrenado\n",
        "```\n",
        "\n",
        "### 6. **Carga de Modelos y Pruebas**\n",
        "El código incluye la carga de cinco versiones diferentes del modelo LSTM. Dependiendo del número de épocas, la calidad del texto generado puede variar. Los modelos se cargan automáticamente en CPU o GPU, según el dispositivo disponible.\n",
        "\n",
        "```python\n",
        "loaded_model_1.load_state_dict(torch.load(model_1_save_path, map_location=device))\n",
        "loaded_model_60.load_state_dict(torch.load(model_60_save_path, map_location=device))\n",
        "loaded_model_150.load_state_dict(torch.load(model_150_save_path, map_location=device))\n",
        "```\n",
        "\n",
        "### 7. **Generación de Cuentos**\n",
        "El usuario puede introducir una secuencia inicial en inglés, y el modelo generará una secuencia de texto basada en esta entrada. Se muestran las salidas de los modelos entrenados épocas para comparar el rendimiento de cada uno.\n",
        "\n",
        "```python\n",
        "prime = \"Once upon a time,\"\n",
        "print(sample(model=loaded_model_1, size=1000, prime=prime))\n",
        "print(sample(model=loaded_model_60, size=1000, prime=prime))\n",
        "print(sample(model=loaded_model_150, size=1000, prime=prime))\n",
        "```\n"
      ],
      "metadata": {
        "id": "nt2KDiyEOxD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descarga de información"
      ],
      "metadata": {
        "id": "eeUvYOC-MT2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsTT-ha414Xz",
        "outputId": "c8b030f6-77e5-443d-b618-8d62cea7edab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-27 17:38:44--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "\rrequirements.txt      0%[                    ]       0  --.-KB/s               \rrequirements.txt    100%[===================>]      53  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-27 17:38:44 (992 KB/s) - ‘requirements.txt’ saved [53/53]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar modelos entrenados"
      ],
      "metadata": {
        "id": "x86tFBSP-IR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_60epoch.pth\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_1epoch.pth\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_10epoch.pth\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_150epoch.pth\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_180epoch.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL2uYeoe-vpo",
        "outputId": "6f72a603-dde7-478e-c5fa-ef708e5bd166"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-27 20:12:26--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_60epoch.pth\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_60epoch.pth [following]\n",
            "--2024-09-27 20:12:26--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_60epoch.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13816956 (13M) [application/octet-stream]\n",
            "Saving to: ‘lstm_cuentos_infantiles_60epoch.pth.2’\n",
            "\n",
            "lstm_cuentos_infant 100%[===================>]  13.18M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-27 20:12:27 (120 MB/s) - ‘lstm_cuentos_infantiles_60epoch.pth.2’ saved [13816956/13816956]\n",
            "\n",
            "--2024-09-27 20:12:27--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_1epoch.pth\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_1epoch.pth [following]\n",
            "--2024-09-27 20:12:27--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_1epoch.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13816949 (13M) [application/octet-stream]\n",
            "Saving to: ‘lstm_cuentos_infantiles_1epoch.pth.2’\n",
            "\n",
            "lstm_cuentos_infant 100%[===================>]  13.18M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-27 20:12:27 (119 MB/s) - ‘lstm_cuentos_infantiles_1epoch.pth.2’ saved [13816949/13816949]\n",
            "\n",
            "--2024-09-27 20:12:28--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_10epoch.pth\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_10epoch.pth [following]\n",
            "--2024-09-27 20:12:28--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_10epoch.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13816956 (13M) [application/octet-stream]\n",
            "Saving to: ‘lstm_cuentos_infantiles_10epoch.pth.2’\n",
            "\n",
            "lstm_cuentos_infant 100%[===================>]  13.18M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-27 20:12:28 (122 MB/s) - ‘lstm_cuentos_infantiles_10epoch.pth.2’ saved [13816956/13816956]\n",
            "\n",
            "--2024-09-27 20:12:28--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_150epoch.pth\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_150epoch.pth [following]\n",
            "--2024-09-27 20:12:28--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_150epoch.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13816956 (13M) [application/octet-stream]\n",
            "Saving to: ‘lstm_cuentos_infantiles_150epoch.pth.2’\n",
            "\n",
            "lstm_cuentos_infant 100%[===================>]  13.18M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-27 20:12:29 (118 MB/s) - ‘lstm_cuentos_infantiles_150epoch.pth.2’ saved [13816956/13816956]\n",
            "\n",
            "--2024-09-27 20:12:29--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_180epoch.pth\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_180epoch.pth [following]\n",
            "--2024-09-27 20:12:29--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_180epoch.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13816963 (13M) [application/octet-stream]\n",
            "Saving to: ‘lstm_cuentos_infantiles_180epoch.pth’\n",
            "\n",
            "lstm_cuentos_infant 100%[===================>]  13.18M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-27 20:12:30 (119 MB/s) - ‘lstm_cuentos_infantiles_180epoch.pth’ saved [13816963/13816963]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar caracteres"
      ],
      "metadata": {
        "id": "IYvbOP36eG8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/chars/chars60.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFbqdWSLeJ20",
        "outputId": "70d297a7-4f3b-46da-b205-6374d0d8b928"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-27 17:38:48--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/chars/chars60.pkl\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/chars/chars60.pkl [following]\n",
            "--2024-09-27 17:38:48--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/chars/chars60.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 519 [application/octet-stream]\n",
            "Saving to: ‘chars60.pkl’\n",
            "\n",
            "chars60.pkl         100%[===================>]     519  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-27 17:38:48 (25.7 MB/s) - ‘chars60.pkl’ saved [519/519]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Quitar comentario de abajo si hay problema con las dependencias\n",
        "#!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "hpff72yTMZQW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c8vXlSpDs7Sp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros del modelo\n",
        "# ------------------------------\n",
        "# n_hidden: Número de unidades en las capas ocultas.\n",
        "n_hidden = 512\n",
        "\n",
        "# n_layers: Número de capas en el modelo LSTM.\n",
        "n_layers = 2\n",
        "\n",
        "# batch_size: Número de ejemplos que se procesan en cada paso de entrenamiento\n",
        "batch_size = 16\n",
        "\n",
        "# top_k: Número de predicciones más probables a considerar al generar nuevo texto.\n",
        "t_k = 7\n",
        "t_k2 = 10"
      ],
      "metadata": {
        "id": "bIUMnmR8_fbR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, chars, n_hidden=n_hidden, n_layers=n_layers, drop_prob=0.5):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_layers = n_layers\n",
        "        self.n_chars = len(chars)\n",
        "        self.char2int = {ch: ii for ii, ch in enumerate(chars)}\n",
        "        self.int2char = dict(enumerate(chars))\n",
        "\n",
        "        self.lstm = nn.LSTM(self.n_chars, n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.fc = nn.Linear(n_hidden, self.n_chars)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        out = self.dropout(r_output)\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "fUPbSups7bh9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funciones de predicción\n",
        "def one_hot_encode(arr, n_labels):\n",
        "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "    return one_hot\n",
        "\n",
        "def predict(model, char, device, h=None, top_k=2):\n",
        "    # Convertir el carácter a su índice entero correspondiente\n",
        "    x = np.array([[model.char2int[char]]])\n",
        "\n",
        "    # Codificar en one-hot\n",
        "    x = one_hot_encode(x, model.n_chars)\n",
        "\n",
        "    # Convertir el array de NumPy a un tensor de PyTorch y moverlo al dispositivo\n",
        "    inputs = torch.from_numpy(x).to(device)\n",
        "\n",
        "    # Desactivar el cálculo de gradiente para predicción\n",
        "    with torch.no_grad():\n",
        "        # Pasada hacia adelante por el modelo\n",
        "        out, h = model(inputs, h)\n",
        "\n",
        "        # Aplicar softmax para obtener probabilidades\n",
        "        p = F.softmax(out, dim=1).data.cpu()\n",
        "\n",
        "        # Obtener los top k caracteres más probables\n",
        "        p, top_ch = p.topk(top_k)\n",
        "\n",
        "        # Convertir a arrays de NumPy\n",
        "        top_ch = top_ch.numpy().squeeze()\n",
        "        p = p.numpy().squeeze()\n",
        "\n",
        "        # Elegir el siguiente carácter basado en las probabilidades\n",
        "        char = np.random.choice(top_ch, p=p/p.sum())\n",
        "\n",
        "    return model.int2char[char], h\n",
        "\n",
        "def sample(model, size, prime='Once upon a time,', top_k=2):\n",
        "    model.eval()  # Cambiar a modo de evaluación\n",
        "    chars = [ch for ch in prime]\n",
        "    h = model.init_hidden(1)  # Inicializar el estado oculto\n",
        "\n",
        "    # Generar los caracteres iniciales\n",
        "    for ch in prime:\n",
        "        char, h = predict(model, ch, device, h=h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    # Generar los caracteres restantes\n",
        "    for _ in range(size):\n",
        "        char, h = predict(model, chars[-1], device, h=h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "metadata": {
        "id": "hcRPLBl72kqb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer el dispositivo (CPU o GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "8HDdbdgHvwfW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv97AIpHCOKI",
        "outputId": "0db33ae2-d8cc-4e5d-f844-8e39eb0bcdec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga y prueba de modelo"
      ],
      "metadata": {
        "id": "9-XmWd-I3LGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar `chars`\n",
        "with open('chars60.pkl', 'rb') as f:\n",
        "    chars = pickle.load(f)"
      ],
      "metadata": {
        "id": "J7gJ5NeFIswl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar el modelo y los pesos guardados\n",
        "#Probar modelo 1 epoca\n",
        "model_1_save_path = \"lstm_cuentos_infantiles_1epoch.pth\"\n",
        "#Probar modelo 10 epocas\n",
        "model_10_save_path = \"lstm_cuentos_infantiles_10epoch.pth\"\n",
        "#Probar modelo 60 epocas\n",
        "model_60_save_path = \"lstm_cuentos_infantiles_60epoch.pth\"\n",
        "#Probar modelo 150 epocas\n",
        "model_150_save_path = \"lstm_cuentos_infantiles_150epoch.pth\"\n",
        "#Probar modelo 180 epocas\n",
        "model_180_save_path = \"lstm_cuentos_infantiles_180epoch.pth\"\n",
        "\n",
        "loaded_model_1, loaded_model_10,loaded_model_60,loaded_model_150,loaded_model_180 = LSTM(chars, n_hidden=n_hidden, n_layers=n_layers).to(device) , LSTM(chars, n_hidden=n_hidden, n_layers=n_layers).to(device), LSTM(chars, n_hidden=n_hidden, n_layers=n_layers).to(device), LSTM(chars, n_hidden=n_hidden, n_layers=n_layers).to(device), LSTM(chars, n_hidden=n_hidden, n_layers=n_layers).to(device)\n",
        "\n",
        "\n",
        "\n",
        "#Carga con GPU o CPU\n",
        "loaded_model_1.load_state_dict(torch.load(model_1_save_path, map_location=device))\n",
        "loaded_model_10.load_state_dict(torch.load(model_10_save_path, map_location=device))\n",
        "loaded_model_60.load_state_dict(torch.load(model_60_save_path, map_location=device))\n",
        "loaded_model_150.load_state_dict(torch.load(model_150_save_path, map_location=device))\n",
        "loaded_model_180.load_state_dict(torch.load(model_180_save_path, map_location=device))\n",
        "\n",
        "loaded_model_1.eval()\n",
        "loaded_model_10.eval()\n",
        "loaded_model_60.eval()\n",
        "loaded_model_150.eval()\n",
        "loaded_model_180.eval()"
      ],
      "metadata": {
        "id": "HWlSBYnSwegy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee749f37-49df-4032-8860-8e34a60cde99"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-b17eb8cdac80>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model_1.load_state_dict(torch.load(model_1_save_path, map_location=device))\n",
            "<ipython-input-52-b17eb8cdac80>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model_10.load_state_dict(torch.load(model_10_save_path, map_location=device))\n",
            "<ipython-input-52-b17eb8cdac80>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model_60.load_state_dict(torch.load(model_60_save_path, map_location=device))\n",
            "<ipython-input-52-b17eb8cdac80>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model_150.load_state_dict(torch.load(model_150_save_path, map_location=device))\n",
            "<ipython-input-52-b17eb8cdac80>:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model_180.load_state_dict(torch.load(model_180_save_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(117, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=117, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generación de cuento"
      ],
      "metadata": {
        "id": "82u_h140FBuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduce aquí el texto inicial para generar el cuento**, recuerda que tiene que ser un texto en inglés.\n",
        "Damos algunas recomendaciones pero puedes poner lo que quieras (máximo 100 caracteres)"
      ],
      "metadata": {
        "id": "H0A88QnCFJHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prime=\"Once upon a time,\"\n",
        "#prime=\"The pretty princess\"\n",
        "#prime=\"\"\"The three little pigs\n",
        "#Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them.\"\"\"\n",
        "#prime=\"\"\"Princess Naomy\n",
        "#Once there lived a beautiful girl named Naomy who was always troubled by \"\"\"\n",
        "\n",
        "prime=\"\"\" Three Little Princesses\n",
        "There lived 3 little princesses Kimmy, Katie, and Kristen with their parents in a manor.\n",
        "There were butlers, maids, cooks, and lots of people to serve them. But both parents and kids were very humble and were really kind to all of them. \"\"\""
      ],
      "metadata": {
        "id": "p6L1AVIkHvj5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prime = prime[:99]"
      ],
      "metadata": {
        "id": "XsxSEjJKIoe5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de 1 época"
      ],
      "metadata": {
        "id": "FLftfuyjKx0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Generar texto con el modelo de 1 epoca\n",
        "\"\"\"generated_text = sample(loaded_model_1, size=1000, prime=\"Once upon a time\")\n",
        "print(generated_text)\"\"\"\n",
        "print(sample(model=loaded_model_1, size=1000, prime=prime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9ld9bsvwTL8",
        "outputId": "80e7e7e1-4ef9-4191-ce60-290e2df0cbfa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Princess Naomy\n",
            "\n",
            "Once there lived a beautiful girl named Naomy who was always troubled by rincess aotre M\"n e toaye ioves tnsiautiful corl aoted aotra aio was t ways thaublid te the court of the court of his hands of the constituting the sound of the care and standing on his heart, the man was a strange chance of the castle and starts, to the sounds of his story and streams, and standing out of the soldier and to the soldier, without a stare and standing of his hand and said to the court at the soldier, and they had been set it on a short and starts and the sound of the strange stares, they had been seen a shop of the strange child that the strange stands on the stare of the way of his head, as they was a shop of the court and stared and said that he was a little best to the cast of their heart and something of this time, to his face with a little bank and throwing the care on the stark of the constinctive counter of the stranger, and the man was straining to his share at the contents, and started and standing and the strange child and the stares of his head of a long strange companions, and took the contrary of the country, and took his hand at his head, and t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_60, size=1000, prime=prime,top_k=t_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IURSpYGRt1H",
        "outputId": "52f87b88-ff43-475f-fc75-c285f46defd6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Princess Naomy\n",
            "\n",
            "Once there lived a beautiful girl named Naomy who was always troubled by rincess.oosni s\"u e uhere haved a seautiful mial,wemed Hetki tho has atrays thiubled ty the second day, and that no one would get the moment when he had finished force, but after the statue there were no man of some story. He wanted to cry fairly, but it was a shabby, friendly work, and the stranger was to be summoned into such a perfectly rough timid table. Suddenly someone saw, and an old man was one of them, however, as if she could hear the promise of their four-and-twenty million shames and then became the least angry was able to send for the size of the teeth that was firmly a monster shine with a hoof and walls on the spot. This was a puzzled truth of all that had happened.\n",
            "They determined to go into the castle in the closet bound of whole time; and he then received a storm of helm; and they went into the horse, took off the butcher, which had begun to get into its beard, standing under a straight bowl-stained air which was behund at the bottom of the head of the captive.\n",
            "The soldier had already heart in the clear terror, and by the trader the sorlows and strewishin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_1, size=1000, prime=prime,top_k=t_k2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e51P2cYAQURT",
        "outputId": "12003d61-5b4a-47d0-fee1-f636f060a9bc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Princess Naomy\n",
            "\n",
            "Once there lived a beautiful girl named Naomy who was always troubled by aingess ieske aTz e hoane woked ttwuautiful forlsteted wetna'Liisaes sslays thuubled be him and was thinking in a fire to the midate of animal had a blackly face of crown to the true his little single to try to with one of simple, he done speaks. On alone, arms, by their sea surashed, and her souls, so boldly certain. The prince would go about him that she turned at her that the miss of his scorns in the troubles of wicked face was then would than a book of the door; so he stood the shoes as he let himself bring out the poor one and had happened to see the ways' another, bitterly through the day, from its shaped tenderly turn. The seat had loseed a such schools again, and then his cheers had seen a sort of the cause.\n",
            "Her put in a seemed pression and startled back and creatures, and followed that he was cut away her less that the pine of water came on, which walked their down that has wildered off, and as side, and from which that shade and the pale shall be a bit of call which they reached it, and the land the there felt a great place with business. He could never stealf t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7mCmEHecfc8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de 10 epocas"
      ],
      "metadata": {
        "id": "tyxxDF9Qfj5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_10, size=1000, prime=prime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpQUveTrfj5K",
        "outputId": "2bbd70f8-c281-40fd-e89c-78228dc5d1f2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Princess Naomy\n",
            "\n",
            "Once there lived a beautiful girl named Naomy who was always troubled by Aincess aatli wAnee mhe e iived tssiautiful morl,wemed Batna,who was a lays aouubled by the station of the countenance of the stable.\n",
            "\"What is there and there are you thinking of?\" asked Jo, as she was all to his father, as he was still a sight.\n",
            "\"Why don't you see her?\" asked the Prince, \"and the more they all says that I was all the words they wish to bring him to the same story. I will not be a man who was to say, because I was always a moment that he had always been a man of the world.  They were so long that he was a good many times against the state of the strength of the contract and the stranger, and was a great deal of the stranger.\n",
            "\"It is a man,\" said the Marionette, who had never seen the children to himself, \"I wish I was to see them.  It is the most affectionate tinger and the complexe of all the world will be able to breathe and see to the command of the story of the stranger.\"\n",
            "\"It isn't the man who will be able to say,\" said the Princess, \"and what a strange sound that is that he was the same time that we can break and see the street at the top, and then they\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_10, size=1000, prime=prime,top_k=t_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETolIxOqfj5K",
        "outputId": "3c543e67-f24a-4f74-e170-8af212f5935b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Princess Naomy\n",
            "\n",
            "Once there lived a beautiful girl named Naomy who was always troubled by Eincess aante,hAn e!mhene wived t plautiful srrl.ioted Jarni.aho was tbmays ahoubled.wy the worse bright and delect for their human same fatiguity to any one; and he had been continually so high and hardly afraid of the same thing have been worse than themselves and she had been in time, as it were. Birds, however, his beard came up and consented, till he told him that any word of the world as they sold him to him, and he saw him with his way.\n",
            "He said, \"I have been surming for any portriatese observation, and will not be such a stort of them. I will say, I have grown from his back against the stand and turn her to the throat.\"\n",
            "\"Why, you will go and see if a steel would have heard this in the society.\"\n",
            "All the children disturbed him, for the birds were once too before they had got a great fruit or a men, while, with a learning, but the same time were all these beloved and comfortable way. They said, \"What is a minute at the side of the convenience of tallow for it? It is tests in my manner and many accounts of that horn.\n",
            "All the postions, and a little gloomy way, to his fam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_10, size=1000, prime=prime,top_k=t_k2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bilslRjafj5K",
        "outputId": "27d76944-936a-4257-fbba-76e1f7855a02"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Princess Naomy\n",
            "\n",
            "Once there lived a beautiful girl named Naomy who was always troubled by Aynce s,Sowli,sSnee ahe e wived b goautiful derl iined Botro bio wasnhwlays choubled.by the head, a poor loddy like a great family angrily however, by honorable human bare-mouth, as attacking itself the school; and however, the small portrait of the cloth was against a woodcutter creamless, the long-day or dead fortune, so that he didn't know, as she waded the two carves and taps in the hollow.\n",
            "Beauty was striking, that he drew over each other on the thickest of the bad, and the old man had described some hinds, and thought that he had not seen him to go away.\n",
            "All the fairy houses that might be a comfort for a speech they were full to watch and furs bark then he, and were comparisod by the fall over water, and intended to draw the man in the wilderness at the marble tree.\n",
            "\"I should like it?\" asked the poor man.\n",
            "\"So I can make myself children again; it is they have a second with with the pair-one shoot me on the wall.\" The peasant looked at it; and so they wished she was sitting by the wolf.\n",
            "\"What care a thing is welp,\" they replied soberly and like a lovely full soft, \"tha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de 60 epocas"
      ],
      "metadata": {
        "id": "UBdJR_R2K0jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_60, size=1000, prime=prime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elxPJqg_DqML",
        "outputId": "279131e6-4481-421d-9f04-22db02a494ba"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parents in a manor.\n",
            "There were butlers, maids, cooks, and lots of people to serve them. But both parents and kids were very humble and were really kind to all of them. aoaee Pittle Mrincess s \n",
            "oe e iives a Tittle Teincess.s ainpi  ai ea, and haighoritith the r sorents wn t son ra Ahe e were net er   aanne, aolki  and sons,of soople ah teeve theis\n",
            "Aut wyth testnts and sins were sery sanaly and sele teadly sild,to t l tf them. The soldier was startled by the story of the complete story, and was so far away and the strangers that had been seen in the world.\n",
            "The man was still so strong and still that they were startled by the children, and the son of the country, which had struck the ship to the country and said in a little sight, as the man, to talk about it at the same time, had been there, but to be able to despair and things and to the story. The monkey stopped, and saw a strong stone strange to stay at home, and then said to her soldiers:\n",
            "“I am a good man, and that I will see them to the stranger that I shall be to the country. I have seen them all to seek the command of the world, and I will stay and see what is the matter with me.”\n",
            "The second thing they were standing on the top of the wall, and the soldier went out of the way, and told her what they were saying. The man said to his father, “I will go and stay there,” and he said he would have them. Then the King’s daughter said to him, “I will see them, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_60, size=1000, prime=prime,top_k=t_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFtsS9vhRoVT",
        "outputId": "dd730c54-b0f6-4cb2-fc38-8a5bfb894ddc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parents in a manor.\n",
            "There were butlers, maids, cooks, and lots of people to serve them. But both parents and kids were very humble and were really kind to all of them. aheee-Eittle Maincess.s  oe e cived a Tettle Jiincess!s ten e  ai he, and tietkoritanhiahe r hardnts an t bet ra\n",
            "Ahe e ware nut ers  byide, wrnte, and ceaa of toaple whgdeeve ihe , Tut teth orstnts wrd dins wore oery cunale and deae iesdly aind to tnl tt theis All the children would not suffer with all its wealthy agitation; and of several times, after a while, they had a large bird into society, without them. They had been with them to be so comfortable as their bed-head, and they took the waters and the boys far, and it could hardly believe the most fishing; for at the same time, the fresh brumme struck a grind blue stone, so that a smile and the shut was some shiverings, and asked the steedy form of two sister how to do as many a thick frost-boat. And he was so fast as they set on the hoot, together, and conceited a lotting chain and threw it up.\n",
            "The boat was floating at it on the floor, and at the season he could not steal immediately to her sad spirit because she had not had fairy tongue for her.\n",
            "The three shames of pines talked on back again from the house, off the wreath-shop, which had cleared, and, threatening to tear himself a comfortable pit that was as good as the foreman all that he was, had not been then to be called and who lef\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_60, size=1000, prime=prime,top_k=t_k2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWUIHJ5kRcv6",
        "outputId": "390c9321-7419-4c14-a13c-ad0faa9c33c0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parents in a manor.\n",
            "There were butlers, maids, cooks, and lots of people to serve them. But both parents and kids were very humble and were really kind to all of them. ahaae Tiotle Faince,s,s;\n",
            "hr e teved a \n",
            "ektle Jiencess   finbi  oa ee. lnd aeighoriaath the r mrrrnts,fn tlsog r \n",
            "Ahe e ware got er   winle, aouk , cnd sivs of maople,hh saave ahe s Tut aeyh fertnts snd tind,oare tery linble tsd wiee wepdly cind,fh t l tu ahem.\n",
            "Now they were all, thinking that they had an end of him.\n",
            "The white stream seemed at the pull in the air, and thus seemed to climb him to the bell. Sparkling looked a long, handsome smile, the crows had said that the fishers had hot forehead, and in everything became as large as ares and silver tubs.\n",
            "\"Oh, if you're got a light turn up.\"\n",
            "\"Oh!\" said he, at happiness, \"tail the worrs, and start to the flower foot, if you are thirty,\" and he came out, seeming to both intimate and sadly inclined; so she asked, \"You shall never stay to the man’s will, and I am dark and down into the trail, and you shall have my own love when it has all mere strong butter.\"\n",
            "Tom said to himself, \"I'm an increased friend.\" He was always like two or three young people, and he told him that the three women were called to come back to less himself, the old woman was acting beautiful. On the time the miller had gone to his country the Princess, who had been a filler successful, went for his son, who had the clerk was\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de 150 epocas"
      ],
      "metadata": {
        "id": "X3xHzptmK-bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_150, size=1000, prime=prime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WdJ3fDjDqpC",
        "outputId": "25e0fca3-4735-4fbd-e58d-caae5fb864a9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parents in a manor.\n",
            "There were butlers, maids, cooks, and lots of people to serve them. But both parents and kids were very humble and were really kind to all of them. toeea Cittle Princesses aoe e wived a0oavtle Riincess s ainbi  aa aa, and taantheg\n",
            "ith the r crptnts,wn tnsonnr- The e ware net er   wodde, aonki, and tina of taople,ah beeve,hhe   Tut teth,trstnts ard mnnniwere aery sunble and sere tiadly aild to t l ht them. The chief of the servants, the son of the child, and the man who had a great deal of treasure, were as brilliant as a story. They wore the straw that had stood before him and told him that he was the most beautiful of a short time. The King was always so far away, and the man was so strange that the maid had to stay at home and to come and take them out of the window and seek the children.\n",
            "\"I will tell you,\" said the maiden. \"What a strange thing you are afraid of you, and I have nothing to do in my power to do it. I will stay at home. I am a great deal of my prison.\" Then said the King, \"I will take a beautiful shoemaker to make them.\"\n",
            "\"What did they have to do with the story of the children they will go to the palace?\" asked the King, and said:\n",
            "\"We are all the same as they are.\"\n",
            "\"I am not sure that I have not been to the country of the chamber of money,\" said the mother.\n",
            "\"Well, I suppose you'll be so good and so much as they are,\" said the child. Then the mother stopped the window and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_150, size=1000, prime=prime,top_k=t_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVOQ4cPofs83",
        "outputId": "f57a3be0-bfa0-48ea-b6bc-78952c853adc"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parents in a manor.\n",
            "There were butlers, maids, cooks, and lots of people to serve them. But both parents and kids were very humble and were really kind to all of them. tHeee-Cuttle Ceences  s.aaere,woved a.tietle Piincess,s oanpa  wi ac  1nd teasthetTeth the r feltnts wn t mannn- The e sare aas or   aonde, arole, and siwe of paaple th sueve the   Tet aeyh oortrts wns wnng were tery manale,and aele taclly aeld,io hnl tf ohem, All are not in that revenge. Having as much portrait and hopeful the morning, they wore their praises and the tall shrewd-clunchings were talking about, and as soon as they were standing beside the child, she sat at the bowling failed and showed as to be her chairs of the world. They had caught her from her chair and began to grind his travelling straw; so then the poor little girl tried to say so much some of its misery as she was sitting towards the single black crown of happy. She would never think of forbund, but she was afraid she was going to get her to the first day after the most close cat, for the brownie had been beginning to sleep, with this stiff air was chased.\n",
            "So as if such a sheep and all her brother had gone, she went out into the room, so as to see that when she had cut out a spirit of teeth, the sun which lived in her head started from the bunge of clumss and she could see the cat.\n",
            "She had no cry out to the bird and her sentence. When it stopped, there was something al\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_150, size=1000, prime=prime,top_k=t_k2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wSErXXJfu5u",
        "outputId": "7432eff7-3c82-487f-e672-08c1ae1c02ea"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parents in a manor.\n",
            "There were butlers, maids, cooks, and lots of people to serve them. But both parents and kids were very humble and were really kind to all of them. oheee Pogtle Brincesses,\n",
            "hrre wived a3tuntle Poiscess s ain e  ainia. tnd Caasthegthth The r plpsnts tn t sig u \n",
            "Whe e iere mai or   bonde  aaul,. ond pina of werple aa tpave them, Aut,sith taltsts and bine were fery panble,tnd bene fesdly sind to tnl st them. From their mother had already been set the practical best of her fields on the central creature, still so hempless that it was survived and put up in the mirrors of the house.\n",
            "In spite of the tortoise, she said to her:\n",
            "\"As well as the orchard, I am struck with the glittering think of his statesticks filled in some oritine crown till you have thought of his meat after this whole state.\"\n",
            "It was the pleasanter occupant a widow began to glance with glass and struggle to see the ships formed over the warm.\n",
            "\"Why, the worst thing it is, sir and so with the major in it the way angry, of course to-morrow,\" said Pinocchio, seated by the pure smoke, opening his frame with a smoke which the scene with influence had been. I ceased sideways, and wandered away. It was taken to him, but the weaver came well. Because he made the cow-beet of a man's angel and life and broke of. He was gone to make the gentleman way to the tiny procession of the palace and the bright last remark, to say: \"I can do no one \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo de 180 epocas"
      ],
      "metadata": {
        "id": "CmAsCB7-ErFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_180, size=1000, prime=prime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIQsIBu8EteI",
        "outputId": "cfed9e50-883d-45fc-e2e2-9b267ec99fd3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parents in a manor.\n",
            "There were butlers, maids, cooks, and lots of people to serve them. But both parents and kids were very humble and were really kind to all of them. toaea Mottle Princesses, he e iived o0tivtle Reinces es ainpe  ai ec, and tianeua wath the r hrptnts an t connry\n",
            "Ahe e ware nus ers  aadde  ahuk,, and tavs af trople ah seeve the   Aut teth testnts tnd tins were tery sunble,tnd sile teally tnnd.ao t l.tf them. They were all the same that they were all thrown on the stable and they were all alone in the county of the Great Stone Face.\n",
            "The cow was always there and then said, \"If the child will be a good man, the old man was a princess without a more sorry fear. The maiden was still alive, but that the stone was a great man who was a great man, and the maiden who had three sons whom the King was the most beautiful prince than he would be a little good, and that the King was the fairest of all the company. The King's son, who had been a little girl without the story, said to her, \"What is this?\"\n",
            "The King said to his father, \"We will stop a little while the man will be a good man and that is the child of the King.\" Then the King said, 'I would have thought that the children were always saying their father, but the stranger was always the only one whom they would have said.\n",
            "\"We have nothing to eat,\" said the Princess, \"and I see that the stones will be all together.\"\n",
            "\"Well, I wish to have that stra\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_180, size=1000, prime=prime,top_k=t_k2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ-N4BA2FMWu",
        "outputId": "91c41ff2-ce86-45f4-9f30-31b95f4e376b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parents in a manor.\n",
            "There were butlers, maids, cooks, and lots of people to serve them. But both parents and kids were very humble and were really kind to all of them. hraue-Beotle Rhinces,es \n",
            "ro e iiked i7Wavtle Teinces es tanpe, watee  wnd Tieceif;seth thy r srrtnts an a tonnf  \"Hene,ware frs er-  warne, tlmk , bnd ben  of prople.ao tleve whem. Tut teth sustdts sfd min ,tere aary panble,and aele oitdly gind.to t l wf them, The company, however, they had come back to their belusters to go the crown bounded over heaven into the ceiling.\n",
            "There was a little fish cracking about the hut, she cried out: \"Do not be afraid, but about fifteen years of advantate! The old man had been waiting there now, and the truth, which I may help them, are a wonderful thing.\"\n",
            "She hastened to strengthen her steadiest horse, and sprang on a piece of cow from a stronger comes from his prayer, at the silence of the house of a carriage, and the witty crush back the hour, and longed to some tall cave in our light.\n",
            "After this her sister flashed about the corner, calling, \"What is the matter? There is my boat that will not be at home to be brought by in this conduct, and if the company will go from on at the same house and hover on the public ball, I shall be dying to live along a girl of a clatter.\"\n",
            "\"Ah, no!\" answered Muishkin, \"and yet I can do wish to go back to your help to me, and that is not without answer.\"\n",
            "\"Are you going to see \n"
          ]
        }
      ]
    }
  ]
}