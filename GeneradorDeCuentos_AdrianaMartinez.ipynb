{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianaleticiamartinez/mcd_deep_learning/blob/main/GeneradorDeCuentos_AdrianaMartinez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Generador de Cuentos Infantiles con LSTM\n",
        "### Adriana Leticia Martinez\n",
        "### Universidad Panamericana\n",
        "\n",
        "Este notebook contiene la implementación de un modelo LSTM para la generación de cuentos infantiles. El modelo fue entrenado utilizando distintos números de épocas (1,10, 60, 150 y 180), y se incluye la posibilidad de probar diferentes modelos entrenados. Los datos de entrenamiento y los caracteres necesarios para realizar la predicción son importados desde archivos externos.\n",
        "\n",
        "## Módulos del Código\n",
        "\n",
        "### 1. **Importación de Modelos y Datos**\n",
        "El código incluye un bloque para descargar los modelos entrenados y los archivos de caracteres necesarios desde una URL pública. Estos modelos incluyen versiones entrenadas con diferentes épocas\n",
        "\n",
        "```python\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_60epoch.pth\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/chars/chars60.pkl\n",
        "```\n",
        "\n",
        "### 2. **Clase LSTM**\n",
        "La clase `LSTM` define la arquitectura del modelo de red neuronal recurrente. Utiliza múltiples capas de LSTM y una capa completamente conectada para la predicción de caracteres.\n",
        "\n",
        "- **Parámetros**:\n",
        "  - `chars`: El conjunto de caracteres utilizados durante el entrenamiento y predicción.\n",
        "  - `n_hidden`: Número de unidades en las capas ocultas.\n",
        "  - `n_layers`: Número de capas LSTM.\n",
        "  - `drop_prob`: Tasa de *dropout* para evitar sobreajuste.\n",
        "\n",
        "\n",
        "### 3. **Función `one_hot_encode`**\n",
        "Esta función toma un arreglo de índices de caracteres y los convierte en una representación *one-hot* para ser utilizada como entrada al modelo.\n",
        "\n",
        "```python\n",
        "def one_hot_encode(arr, n_labels):\n",
        "    # Codifica el arreglo de índices en formato one-hot\n",
        "```\n",
        "\n",
        "### 4. **Función `predict`**\n",
        "La función `predict` predice el siguiente carácter utilizando el modelo entrenado. Utiliza la salida de la red LSTM para aplicar una función *softmax* y obtener las probabilidades de los caracteres siguientes más probables.\n",
        "\n",
        "- **Parámetros**:\n",
        "  - `model`: El modelo LSTM entrenado.\n",
        "  - `char`: El carácter actual utilizado para generar la predicción.\n",
        "  - `device`: El dispositivo (CPU o GPU) en el que se ejecuta el modelo.\n",
        "  - `h`: El estado oculto del modelo.\n",
        "\n",
        "```python\n",
        "def predict(model, char, device, h=None, top_k=5):\n",
        "    # Predice el siguiente carácter en la secuencia\n",
        "```\n",
        "\n",
        "### 5. **Función `sample`**\n",
        "La función `sample` es la encargada de generar una secuencia de texto a partir de un modelo entrenado y una secuencia inicial (`prime`). Va generando caracteres de manera recurrente basándose en la predicción del carácter más probable.\n",
        "\n",
        "- **Parámetros**:\n",
        "  - `model`: El modelo LSTM cargado.\n",
        "  - `size`: La cantidad de caracteres que se desea generar.\n",
        "  - `prime`: La secuencia inicial con la que se inicia la generación de texto.\n",
        "  - `top_k`: Número de caracteres más probables a considerar en cada predicción.\n",
        "\n",
        "```python\n",
        "def sample(model, size, prime='Once upon a time,', top_k=5):\n",
        "    # Genera una secuencia de texto a partir del modelo entrenado\n",
        "```\n",
        "\n",
        "### 6. **Carga de Modelos y Pruebas**\n",
        "El código incluye la carga de cinco versiones diferentes del modelo LSTM. Dependiendo del número de épocas, la calidad del texto generado puede variar. Los modelos se cargan automáticamente en CPU o GPU, según el dispositivo disponible.\n",
        "\n",
        "```python\n",
        "loaded_model_1.load_state_dict(torch.load(model_1_save_path, map_location=device))\n",
        "loaded_model_60.load_state_dict(torch.load(model_60_save_path, map_location=device))\n",
        "loaded_model_150.load_state_dict(torch.load(model_150_save_path, map_location=device))\n",
        "```\n",
        "\n",
        "### 7. **Generación de Cuentos**\n",
        "El usuario puede introducir una secuencia inicial en inglés, y el modelo generará una secuencia de texto basada en esta entrada. Se muestran las salidas de los modelos entrenados épocas para comparar el rendimiento de cada uno.\n",
        "\n",
        "```python\n",
        "prime = \"Once upon a time,\"\n",
        "print(sample(model=loaded_model_1, size=1000, prime=prime))\n",
        "print(sample(model=loaded_model_60, size=1000, prime=prime))\n",
        "print(sample(model=loaded_model_150, size=1000, prime=prime))\n",
        "```\n"
      ],
      "metadata": {
        "id": "nt2KDiyEOxD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descarga de información"
      ],
      "metadata": {
        "id": "eeUvYOC-MT2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsTT-ha414Xz",
        "outputId": "084687e6-e7fa-428d-fa3c-f95d09fed2c8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-27 22:26:14--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53 [text/plain]\n",
            "Saving to: ‘requirements.txt.1’\n",
            "\n",
            "\rrequirements.txt.1    0%[                    ]       0  --.-KB/s               \rrequirements.txt.1  100%[===================>]      53  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-27 22:26:14 (816 KB/s) - ‘requirements.txt.1’ saved [53/53]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar modelos entrenados"
      ],
      "metadata": {
        "id": "x86tFBSP-IR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_60epoch.pth\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_1epoch.pth\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_10epoch.pth\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_150epoch.pth\n",
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_180epoch.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL2uYeoe-vpo",
        "outputId": "04e798e1-03c2-4f28-a0a5-3b27c9df1415"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-27 22:26:14--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_60epoch.pth\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_60epoch.pth [following]\n",
            "--2024-09-27 22:26:14--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_60epoch.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13816956 (13M) [application/octet-stream]\n",
            "Saving to: ‘lstm_cuentos_infantiles_60epoch.pth.3’\n",
            "\n",
            "lstm_cuentos_infant 100%[===================>]  13.18M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-27 22:26:15 (97.2 MB/s) - ‘lstm_cuentos_infantiles_60epoch.pth.3’ saved [13816956/13816956]\n",
            "\n",
            "--2024-09-27 22:26:15--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_1epoch.pth\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_1epoch.pth [following]\n",
            "--2024-09-27 22:26:15--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_1epoch.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13816949 (13M) [application/octet-stream]\n",
            "Saving to: ‘lstm_cuentos_infantiles_1epoch.pth.3’\n",
            "\n",
            "lstm_cuentos_infant 100%[===================>]  13.18M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-27 22:26:16 (89.9 MB/s) - ‘lstm_cuentos_infantiles_1epoch.pth.3’ saved [13816949/13816949]\n",
            "\n",
            "--2024-09-27 22:26:16--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_10epoch.pth\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_10epoch.pth [following]\n",
            "--2024-09-27 22:26:16--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_10epoch.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13816956 (13M) [application/octet-stream]\n",
            "Saving to: ‘lstm_cuentos_infantiles_10epoch.pth.3’\n",
            "\n",
            "lstm_cuentos_infant 100%[===================>]  13.18M  82.3MB/s    in 0.2s    \n",
            "\n",
            "2024-09-27 22:26:17 (82.3 MB/s) - ‘lstm_cuentos_infantiles_10epoch.pth.3’ saved [13816956/13816956]\n",
            "\n",
            "--2024-09-27 22:26:17--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_150epoch.pth\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_150epoch.pth [following]\n",
            "--2024-09-27 22:26:18--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_150epoch.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13816956 (13M) [application/octet-stream]\n",
            "Saving to: ‘lstm_cuentos_infantiles_150epoch.pth.3’\n",
            "\n",
            "lstm_cuentos_infant 100%[===================>]  13.18M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-27 22:26:18 (100 MB/s) - ‘lstm_cuentos_infantiles_150epoch.pth.3’ saved [13816956/13816956]\n",
            "\n",
            "--2024-09-27 22:26:18--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/models/charModels/lstm_cuentos_infantiles_180epoch.pth\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_180epoch.pth [following]\n",
            "--2024-09-27 22:26:19--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/models/charModels/lstm_cuentos_infantiles_180epoch.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13816963 (13M) [application/octet-stream]\n",
            "Saving to: ‘lstm_cuentos_infantiles_180epoch.pth.1’\n",
            "\n",
            "lstm_cuentos_infant 100%[===================>]  13.18M  82.2MB/s    in 0.2s    \n",
            "\n",
            "2024-09-27 22:26:19 (82.2 MB/s) - ‘lstm_cuentos_infantiles_180epoch.pth.1’ saved [13816963/13816963]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar caracteres"
      ],
      "metadata": {
        "id": "IYvbOP36eG8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/chars/chars60.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFbqdWSLeJ20",
        "outputId": "0515aee3-d3fe-4b1a-c015-26110f2c1bf5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-27 22:26:19--  https://github.com/adrianaleticiamartinez/mcd_deep_learning/raw/refs/heads/main/chars/chars60.pkl\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/chars/chars60.pkl [following]\n",
            "--2024-09-27 22:26:19--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/chars/chars60.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 519 [application/octet-stream]\n",
            "Saving to: ‘chars60.pkl.1’\n",
            "\n",
            "\rchars60.pkl.1         0%[                    ]       0  --.-KB/s               \rchars60.pkl.1       100%[===================>]     519  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-27 22:26:20 (23.2 MB/s) - ‘chars60.pkl.1’ saved [519/519]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Quitar comentario de abajo si hay problema con las dependencias\n",
        "#!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "hpff72yTMZQW"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "c8vXlSpDs7Sp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "RPba40lZlyt9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros del modelo\n",
        "# ------------------------------\n",
        "# n_hidden: Número de unidades en las capas ocultas.\n",
        "n_hidden = 512\n",
        "\n",
        "# n_layers: Número de capas en el modelo LSTM.\n",
        "n_layers = 2\n",
        "\n",
        "# batch_size: Número de ejemplos que se procesan en cada paso de entrenamiento\n",
        "batch_size = 16\n",
        "\n",
        "# top_k: Número de predicciones más probables a considerar al generar nuevo texto.\n",
        "t_k = 7\n",
        "t_k2 = 10"
      ],
      "metadata": {
        "id": "bIUMnmR8_fbR"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, chars, n_hidden=n_hidden, n_layers=n_layers, drop_prob=0.5):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_layers = n_layers\n",
        "        self.n_chars = len(chars)\n",
        "        self.char2int = {ch: ii for ii, ch in enumerate(chars)}\n",
        "        self.int2char = dict(enumerate(chars))\n",
        "\n",
        "        self.lstm = nn.LSTM(self.n_chars, n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.fc = nn.Linear(n_hidden, self.n_chars)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        out = self.dropout(r_output)\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "fUPbSups7bh9"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funciones de predicción\n",
        "def one_hot_encode(arr, n_labels):\n",
        "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "    return one_hot\n",
        "\n",
        "def predict(model, char, device, h=None, top_k=2):\n",
        "    # Convertir el carácter a su índice entero correspondiente\n",
        "    x = np.array([[model.char2int[char]]])\n",
        "\n",
        "    # Codificar en one-hot\n",
        "    x = one_hot_encode(x, model.n_chars)\n",
        "\n",
        "    # Convertir el array de NumPy a un tensor de PyTorch y moverlo al dispositivo\n",
        "    inputs = torch.from_numpy(x).to(device)\n",
        "\n",
        "    # Desactivar el cálculo de gradiente para predicción\n",
        "    with torch.no_grad():\n",
        "        # Pasada hacia adelante por el modelo\n",
        "        out, h = model(inputs, h)\n",
        "\n",
        "        # Aplicar softmax para obtener probabilidades\n",
        "        p = F.softmax(out, dim=1).data.cpu()\n",
        "\n",
        "        # Obtener los top k caracteres más probables\n",
        "        p, top_ch = p.topk(top_k)\n",
        "\n",
        "        # Convertir a arrays de NumPy\n",
        "        top_ch = top_ch.numpy().squeeze()\n",
        "        p = p.numpy().squeeze()\n",
        "\n",
        "        # Elegir el siguiente carácter basado en las probabilidades\n",
        "        char = np.random.choice(top_ch, p=p/p.sum())\n",
        "\n",
        "    return model.int2char[char], h\n",
        "\n",
        "def sample(model, size, prime='Once upon a time,', top_k=2):\n",
        "    model.eval()  # Cambiar a modo de evaluación\n",
        "    chars = [ch for ch in prime]\n",
        "    h = model.init_hidden(1)  # Inicializar el estado oculto\n",
        "\n",
        "    # Generar los caracteres iniciales\n",
        "    for ch in prime:\n",
        "        char, h = predict(model, ch, device, h=h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    # Generar los caracteres restantes\n",
        "    for _ in range(size):\n",
        "        char, h = predict(model, chars[-1], device, h=h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "metadata": {
        "id": "hcRPLBl72kqb"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer el dispositivo (CPU o GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "8HDdbdgHvwfW"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv97AIpHCOKI",
        "outputId": "20f2885d-b7d2-4331-eb99-fb9716a1bf69"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga y prueba de modelo"
      ],
      "metadata": {
        "id": "9-XmWd-I3LGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar `chars`\n",
        "with open('chars60.pkl', 'rb') as f:\n",
        "    chars = pickle.load(f)"
      ],
      "metadata": {
        "id": "J7gJ5NeFIswl"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar el modelo y los pesos guardados\n",
        "#Probar modelo 1 epoca\n",
        "model_1_save_path = \"lstm_cuentos_infantiles_1epoch.pth\"\n",
        "#Probar modelo 10 epocas\n",
        "model_10_save_path = \"lstm_cuentos_infantiles_10epoch.pth\"\n",
        "#Probar modelo 60 epocas\n",
        "model_60_save_path = \"lstm_cuentos_infantiles_60epoch.pth\"\n",
        "#Probar modelo 150 epocas\n",
        "model_150_save_path = \"lstm_cuentos_infantiles_150epoch.pth\"\n",
        "#Probar modelo 180 epocas\n",
        "model_180_save_path = \"lstm_cuentos_infantiles_180epoch.pth\"\n",
        "\n",
        "loaded_model_1, loaded_model_10,loaded_model_60,loaded_model_150,loaded_model_180 = LSTM(chars, n_hidden=n_hidden, n_layers=n_layers).to(device) , LSTM(chars, n_hidden=n_hidden, n_layers=n_layers).to(device), LSTM(chars, n_hidden=n_hidden, n_layers=n_layers).to(device), LSTM(chars, n_hidden=n_hidden, n_layers=n_layers).to(device), LSTM(chars, n_hidden=n_hidden, n_layers=n_layers).to(device)\n",
        "\n",
        "\n",
        "\n",
        "#Carga con GPU o CPU\n",
        "loaded_model_1.load_state_dict(torch.load(model_1_save_path, map_location=device))\n",
        "loaded_model_10.load_state_dict(torch.load(model_10_save_path, map_location=device))\n",
        "loaded_model_60.load_state_dict(torch.load(model_60_save_path, map_location=device))\n",
        "loaded_model_150.load_state_dict(torch.load(model_150_save_path, map_location=device))\n",
        "loaded_model_180.load_state_dict(torch.load(model_180_save_path, map_location=device))\n",
        "\n",
        "loaded_model_1.eval()\n",
        "loaded_model_10.eval()\n",
        "loaded_model_60.eval()\n",
        "loaded_model_150.eval()\n",
        "loaded_model_180.eval()"
      ],
      "metadata": {
        "id": "HWlSBYnSwegy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2aff1b6-9439-4854-d34b-db22a463eeaf"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(117, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=117, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generación de cuento"
      ],
      "metadata": {
        "id": "82u_h140FBuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduce aquí el texto inicial para generar el cuento**, recuerda que tiene que ser un texto en inglés.\n",
        "Damos algunas recomendaciones pero puedes poner lo que quieras (máximo 100 caracteres)"
      ],
      "metadata": {
        "id": "H0A88QnCFJHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prime=\"Once upon a time,\"\n",
        "#prime=\"The pretty princess\"\n",
        "#prime=\"\"\"The three little pigs\n",
        "#Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them.\"\"\"\n",
        "#prime=\"\"\"Princess Naomy\n",
        "#Once there lived a beautiful girl named Naomy who was always troubled by \"\"\"\n",
        "\n",
        "prime=\"\"\" Three Little Princesses\n",
        "There lived 3 little princesses Kimmy, Katie, and Kristen with their parents in a manor.\n",
        "There were butlers, maids, cooks, and lots of people to serve them. But both parents and kids were very humble and were really kind to all of them. \"\"\""
      ],
      "metadata": {
        "id": "p6L1AVIkHvj5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prime = prime[:99]"
      ],
      "metadata": {
        "id": "XsxSEjJKIoe5"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de 1 época"
      ],
      "metadata": {
        "id": "FLftfuyjKx0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Generar texto con el modelo de 1 epoca\n",
        "\"\"\"generated_text = sample(loaded_model_1, size=1000, prime=\"Once upon a time\")\n",
        "print(generated_text)\"\"\"\n",
        "print(sample(model=loaded_model_1, size=1000, prime=prime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9ld9bsvwTL8",
        "outputId": "0d75eeb2-c394-4298-cb42-e4dda151cff1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their paren heoe Wattle Mrincess,s aha e woved an ottle Moince,s s oin  , witea  and taadh r walh aheir sastnce, and she was so many time and so to the strange strange strength of their strange country at the stranger and strange the course, and the strange case was a look of the sound of the stranger and the soul of a start, and the more the most sounded at the care and some side of the strength, which had seen his shoulders and strength at him as he had been seen to the care of the soldier, and he heard the soldier and this way to the stranger as they were so standing to his head at the country to the courtes and took the contents and the castle and started to her a sharp that, and they was so much, and he had been settled themselves, and, and too started at her hands, and he was strong the best of the stares, and that the state were so sure to him and stood at the street of the country and the court at her hand at the state, when this thing that he was standing on the conscious of the stares, and show them, and that the man was standing at the sound of the stares and strength and through th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_60, size=1000, prime=prime,top_k=t_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IURSpYGRt1H",
        "outputId": "8ba8b3f3-1f65-4aff-871a-836bb5c647be"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parensHaoe Pootle Mrincesses,\n",
            "here weves t taktle Jaincess s ahnau  baree  tld aaithoriiilh hhe r srients; from the morning at all. They threw their fun to show their friends, and after came dancing into his friend as if they were their heads. This then threatened to do and see, he thought also.\n",
            "After a little while the team came and said, \"I am hungry and holding to them, full of white shadows and the furious porcestors of a strong subject. In ambush, I shall never look out but the stately wolf, if they must be the man to do it. I am a lot, as well as your family; it will not be allowed to make a stenner. They are their songs, and that want a fire, this writer so long, the sun will cease at once; and, as ten minutes ago has consented to me, it is the foolish woman of your shaking husband and servant and thanks to it. When the father and Queen have stayed here, the sun shut all these and sit down and sleep off in the body of the father that has striked the bedside, who wishes to start herself with a beautiful wheat in the sun and the fright. And all this weeks that the funniest child was\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_1, size=1000, prime=prime,top_k=t_k2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e51P2cYAQURT",
        "outputId": "e57ab5d0-c753-4692-d567-912091a2edf9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parentraee Pigtle Moincess s,aaa e hiked s hittle Wrence,s d oinb . hi emn\"and tiath r wilhithe r harent they related their two but, it was a second, and such limining of work to go scene and cheek. Where asked it along. And when they decled and being hard off. It came on uplited its safes of sperm and white happily into the middle of wad as they was a good shadow, by the during the sort of companions and warmer story of the man, and her husband he discovered out its castle to such a bank as she tribled in the door.  Maral Sharbahs and Bed one's from a first how, who baded the floor. So a great secret of the care, who stared the half.\n",
            "They laughed from the tree bit again, but the place so much at all and three on wish, the delipity sat down the tail. The lagy and barts was began to hunt to him by toiches. And to help it, at last it could not have happened, they rashed for her and fish-song. The man’s shoo that he resided the sight after the coal that had not let him talk against their pulling his specials of his turn upon an asserching that after the bied with the waitings an old, hrimed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7mCmEHecfc8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de 10 epocas"
      ],
      "metadata": {
        "id": "tyxxDF9Qfj5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_10, size=1000, prime=prime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpQUveTrfj5K",
        "outputId": "413110a2-b841-4960-d274-bea3167522aa"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their paren Huee Piotle Mrincess s woa e waved i7 iktle Toisce,s s aitpe  ai es, wnd tianeln whlh ahe r hartnts, and the sea were all at the time.  The contents of the content on herself was the same sight, as the story of the stars and things were all the sort of a man who had no sorts, and they were a great deal of truth, and was a great deal of stories any more than a short time.\n",
            "\"I will go to the castle,\" said the Princess.\n",
            "\"I wish to be so still as that is a story and some one on the streets, and to the carriage of the window, and so that the sun shone in the water.  I was all the same time that the story of the consciousness of the way that was a good deal of the stranger. The most comfortable strength of the way the second time they were a great deal of something to him as they were always so frightened.  They were so still that he was always to be settled at the time of the street.  So the maiden was still still and he stood up and started and stood at the same time.\n",
            "\"What is it?\" said the Princess, \"the most anger, the most angel on her sister, as they are to see the children, and tha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_10, size=1000, prime=prime,top_k=t_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETolIxOqfj5K",
        "outputId": "4d0b14c5-8867-418e-d3ba-b4c50ff40e46"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parenahoee Seotle Maincess s the e oived w6\n",
            "iktle Slovcess s antme  ahtess and taage,ntholh ohe r cectnts, which and thousand hearts seized her head at their faces, and if there are customs at all sorrow for them to hear of the wife, without saying that she was asked with the sake, but as a man wonder of a singularly mortified purity, to appally any means, was his confusion filled, and an answer he had not consented truth. It came up a porture of a mighty man in the state of those what she said in spoiling it.\n",
            "They restabled with him with his hands, of all his music that his half could spoke again in it.\n",
            "\"Yes, the prince. You will be alive. I speak all of his magic things to make the coming of the whole thing to my dearly assistance. And it's a most bistorical single wolf, it were all mine, full and foolish, the marches of having stuck on a stray, and she met, as they didn't know what is her that I had believed to say what is with them?\"\n",
            "\"Oh, don't grow!\" asked John; \"but we have had had you been a sea-light.\"\n",
            "\"As I were off to your pocket, must hear anyone to seek me again, it won't be \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_10, size=1000, prime=prime,top_k=t_k2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bilslRjafj5K",
        "outputId": "af0ab92c-5377-4b45-8206-0e98ac2c2d13"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their paren oeoe Diotle Maincess s whi e weved i8Moktle waesces  s.ohnpe  aa e,s and ioase r wath thesr hartnts. I was a great money from a friend. After all all the states shall soon be soon out of hat and doing it. If any whale, the beautiful bill in those first strangers were. Snow-white fought to be out there, and then as more in the flow of the bottom of the fellow!\n",
            "The cloak will not be certain that her bieting, of the truth, and without all many consent.  Of charge between the full whip his horse and sulfen and sait in a few months.  He had those who have been himself the money, or be our pine cause of him of splittering; her box would be hard by a company of silence and from the shepherd. And never till the cask of two hours or since she would have had of the large wine came in corner; and that they sometimes a coming from the four torches came through the dark floor, and the pile of pride is stopped, and a potetal one from beneath which the people were the peaceed bottoms of the silk and hither. So the family was not to be covered with an high cump in it.\n",
            "There was a beggar boy; and h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de 60 epocas"
      ],
      "metadata": {
        "id": "UBdJR_R2K0jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_60, size=1000, prime=prime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elxPJqg_DqML",
        "outputId": "b30975f7-f8f6-4940-aab9-115685204818"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parenahaee Eittle Maincess s,aoere iaved a Tittle Toincess.s aanbi- aa ea, wnd tiithoritilh ahe r frrents, and the stranger to the strange thing of the wine and all the strange things when the strange stranger heard the sound of their heads. And when they were all the same that the man was aloud, he saw that the child had been so strong and heavy that his father had been so fair and so strong that his manners were so sorry that he had already begun to stay at home. The street was so beautiful to the country and a beautiful maiden, who had the soldier to set him away and seek his sister and her mother the most delicate son of the children who had been to be a boy who held themselves in their heads. The man sat down on the ship with his fingers in the sack, and said to the boy, “I will seek thee all the while, and then you will stay at home to the wood to seek any of them. I have a good fool, and, after all, I wonder what is to be done. I will talk to you to the strength of my heart, and the story, and a strange thing, as if you were all about to stay and wish that I had a single shape on \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_60, size=1000, prime=prime,top_k=t_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFtsS9vhRoVT",
        "outputId": "c520eb79-2d9d-4354-8298-ae0b8e3d8197"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their paren aree Eittle Srince'ses,\n",
            "oe e wived a0Aivtle Beince.s s.ainmi. balia; a d tiithoritith mhe r prrtnts a mole fill and state for their second box. The father comes with a stranger a child and will so take off his place, and take in a cape by the town.\n",
            "\"I want him to believe,\" he said. \"It was it whatever I said they stared on him, for I had been a grating to any worse in at home a little.\"\n",
            "\"If I was it in a sign or delight he sats have so much of it.\"\n",
            "\"In the wood a third time! I'm getting often at him.\"\n",
            "\"I don't want to be sacred that way that would be off, I have the supply of mighty blood in that hint of sinner, and which your confessions have been believed for assistance to all his behaviour with your men in infristation.\n",
            "In this trick of strong, secrets, he wrote.\"\n",
            "\"If we may have had the same animal all over at the sight,\" she cried.\n",
            "\"Yes!\" said Mr. Renshaw.\n",
            "\"Yes, that's all,\" answered Betty sadly, \"but that will go to burst at the whole of a maiden.\n",
            "\"It's all one, whether he wouldn't come, I'm able to suspect you' was the simple man of the country, for instance it has taught me\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_60, size=1000, prime=prime,top_k=t_k2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWUIHJ5kRcv6",
        "outputId": "632c326e-e193-4e0a-aab7-e5e4abfcc06e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parenTHeee-Eittle Jrancess s;ahere waved t Aaktle Bience s s aense  titie’ and hiotkoriahth hhosr hrstnts, or the crier; for the woman was still brilliant through the wrap of the wells, where she lay above his horse, and with the leaves to pet the mouse; and she commanded the corner the bonny hare who leaded it to her short daughters.\n",
            "\"She wants to happen far before her. I've a blighted thing to tell you, but tell me that an emotion should be stolen in, yet I am sure it will be done; but is mine set through that hall with them with dead thunderstands with a few persons who is in confusion in the air-and-five, and these! there is the tlother-camelly.\"\n",
            "When Jennie began to laugh, and suddenly as she had no particular things, he hoped in spite of it, as if he knew that the woman would have been the old dignity for the little boy in the woods-wedges.\n",
            "Then he turned back and cried out:\n",
            "\"Go to a hundred o'clock, and the brass is new before she comes to the cottage language that is chief tree to the city?\"\n",
            "\"No!\" said the Prince, till the marks they had told the children.\n",
            "\"Never mind,\" said the \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de 150 epocas"
      ],
      "metadata": {
        "id": "X3xHzptmK-bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_150, size=1000, prime=prime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WdJ3fDjDqpC",
        "outputId": "1460d74c-7f72-4cd6-8d72-e9d9b34a8405"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their paren heee Cottle Trince ses \n",
            "oe e wived t0hittle Tiincess s wanba  ai ea, and tailthsd\n",
            "ith ahe r crpents, who were to be their children and set out on the town which was a golden coal.\n",
            "The servants were always still so far away that the mother was so frightened, that the man stooped and said to her son, \"I will give you the contents of a charming child, and when you have brought you all over again, you will break my brother and me all the way.\"\n",
            "This the King said to him, \"Well, I will go away again.\"\n",
            "The man went to him and told him how the man was thinking about this.\n",
            "\"I want to go and see him, that I want to see him and to be sure,\" answered the man.\n",
            "Then the King said to his master, \"I will give to you all the way to the country of the King, and then I will go to the King and the King. I will take a stranger to this part of the world. I am a good man. He will be the only one of my pretty son and his wife. If you will not have the story to me at once, I shall have to see you all. I want to go and take a short thing to take the bargain of thee. I am sorry, but I am so sorry that I am a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_150, size=1000, prime=prime,top_k=t_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVOQ4cPofs83",
        "outputId": "14547441-833c-4a86-fef2-6825c6cdd63b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their parenhoeoe Mootle Saincesses.Toere woved a8oektle Beincess s wnnba, aisee  wnd aaasthecCath ahe r honents who had at the end of the chorus, at the same time the mornings of the fleece which they were. A song of shabby water was behind the faces of a big cabinet wide, two of which was not long before when she came into the country, seven tender figures aboard, for she had no meal and both of so much face: thinking whether she had dasced at one beautiful confusion, she would come to the table to play. This made her charm to the children, and went by. The sun was almost in a sharp pitcher.\n",
            "When the time came the plain, and bade out of its common foed. They swam back into the backgrounds of the banker, and the cruel child called to them to show how still they would carry to her.\n",
            "When the time came to his wife, when he had frowned with his strong cottage, the servants was almost to be too larger than the same person in the world, and said that he had a boarding-room to cross his home.\n",
            "When his step-mother danced him was at the back of the forest, there he settled about and took a pond, opened\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_150, size=1000, prime=prime,top_k=t_k2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wSErXXJfu5u",
        "outputId": "675b4218-c794-496c-eb25-efc94413528a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their paren Heee Liltle Waincesses,owe e waved t0oevtle Roincess:s ainbo  ahmaa. wnd haostsiiaath ahe r prgrnts, finishing the hunting man, who had found a glance full of wrongs where he took an arrow bloodless insult to thee.\n",
            "On this tower of the screen, one of the man was opened without much reason, and only said amused upon her way, and had heard a few hours that the pig was coldly and golden. He carried him back into the river, and pleaded his human brother and sares how leaned for faithful mother that a most most combined craft can cover the whole of the house.\n",
            "A loud soldier began to let the old walt this done that he could devour them, and when he saw her, she came to a country and said:\n",
            "\"How did the mother stop shelter from our bed-logged fervents? It is all her father! And then you will be too glad to help you see how struck with the present morning. He is a splendid bird that he has first seen. His wife has no story to me into the house; and trying to set his head out of the city to my wife and a child,' and looked at the lord. I do hope he thought that the sound can be seen a soldie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo de 180 epocas"
      ],
      "metadata": {
        "id": "CmAsCB7-ErFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_180, size=1000, prime=prime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIQsIBu8EteI",
        "outputId": "384e89d6-5ea3-4ec5-ad87-b948dfa7022f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their paren oeee-Cittle Reincesses  oe e wived a mittle Reinces es,winme  wa ac, wnd tiedeua,aath thr r hrptnts and stories to the court of the Stranger-man, and they were to be a sort of servant, who had the same story of his friend and the mother, who had a great many things that she was the most contented woman with the children. The maiden wanted to go to the prince, who had a great deal of song with the sheep, which was that her husband had been so strong and happy.\n",
            "She had never seen her, and that she was all that she was to be able to send her a sharp stone to the castle and see her so short that he was a sheep and a stranger, who was to be able to go to the King of his country.\n",
            "The man went to the King and said, “I will see the prince and the King and the King and their friends.” The maiden said, “I will give you a good deal to be the most beautiful,” said the man.\n",
            "“What are you to do?” says the man, “I will go to the widow and take the words.”\n",
            "“Where are you going to do to this morning?” said the old woman, and she said, \n",
            "“Where is the fire?”\n",
            "“What do you want to?” she asked, and she \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(model=loaded_model_180, size=1000, prime=prime,top_k=t_k2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ-N4BA2FMWu",
        "outputId": "e3297819-a3f2-4bb6-b384-985422e4ad70"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Three Little Princesses\n",
            "There lived 3 little princesses Kimmy, Katie, and Kristen with their paren huoe Pettle Geincess.s \n",
            "or e iikes a0Wattle Gainces es widse, audic  wnd tiancua;hhth ahe r fattnts and sailors. They had studied another, for what his story at all were the sun and wall of my farewell; before the white horse howled, silently perceiving when the horn was closed. There my father stood between the glass on the heavy, downtitted whime, and then the blood looked up. The whole town seemed as if the ship told me that it wadn't and announced, and I was tired and surling milk and cups; I was always desperately worried narrow, and a pigconger lose, at the window of the flower of a sea-brown.\n",
            "“As for the face,” said he.\n",
            "“I won’t been at tiny town.” And he replied, “Now I can fly to his mother, and have something to do. I can’t do so much this horse. I don’t believe he who stretches it far away in her hair and step forth about well.”\n",
            "Before the little goose-woman wanted to brought some heat over them, again when they were stealthily, Shere Khan was sitting from their birds and shouted:\n",
            "“Yes, that is not the thing I haven't!”\n",
            "At this place, the bird was a small weak servant in\n"
          ]
        }
      ]
    }
  ]
}