{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOSYnuxnzXODgYxdt6AZESV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianaleticiamartinez/mcd_deep_learning/blob/main/CharsParaCuentos_AdrianaMartinez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento de Texto para Generador de Cuentos con LSTM\n",
        "\n",
        "Este notebook prepara el texto que se usa para enseñar a un modelo a crear historias para niños usando un modelo LSTM. El objetivo es transformar el texto original en letras únicas y crear los mapas necesarios para que el modelo LSTM pueda procesar secuencias de texto en forma de números.\n",
        "\n",
        "## Objetivos del Notebook\n",
        "\n",
        "1. **Preprocesar el texto**: Convertir el corpus de cuentos infantiles en un conjunto de caracteres únicos, y generar los diccionarios que mapean caracteres a índices enteros y viceversa.\n",
        "2. **Codificar el texto**: Traducir el texto completo a una secuencia de enteros utilizando los diccionarios de mapeo generados.\n",
        "3. **Guardar los datos preprocesados**: Exportar los caracteres únicos, los diccionarios de mapeo y el texto codificado para su uso posterior en el entrenamiento del modelo LSTM.\n",
        "\n",
        "## Descripción del Proceso\n",
        "\n",
        "### 1. **Preprocesamiento del Texto**\n",
        "   - Se importa el corpus de cuentos infantiles desde un archivo de texto limpio. Este archivo contiene cuentos infantiles adecuados para el público joven y ha sido previamente limpiado para eliminar información innecesaria, como metadatos o contenido no relevante.\n",
        "   - El preprocesamiento se realiza mediante la función `preprocess_text`, que convierte el texto en un conjunto de caracteres únicos y genera los diccionarios de mapeo necesarios.\n",
        "\n",
        "### 2. **Diccionarios de Mapeo**\n",
        "   - **`chars`**: Un conjunto de caracteres únicos presentes en el corpus de texto.\n",
        "   - **`int2char`**: Un diccionario que mapea índices enteros a caracteres.\n",
        "   - **`char2int`**: Un diccionario que mapea caracteres a índices enteros.\n",
        "   - **`encoded`**: El texto completo codificado como una secuencia de enteros, donde cada entero representa un carácter del texto original.\n",
        "\n",
        "### 3. **Carga del Corpus de Texto**\n",
        "   - El corpus de cuentos infantiles se descarga de un repositorio y se carga en el notebook utilizando el siguiente comando:\n",
        "     ```python\n",
        "     !wget https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/cleaned_merged_fairy_tales_without_eos.txt\n",
        "     ```\n",
        "   - Luego, se lee el archivo de texto utilizando el bloque `with open`, y se procesa para extraer los caracteres y generar los diccionarios correspondientes.\n",
        "\n",
        "### 4. **Función `preprocess_text`**\n",
        "   La función `preprocess_text` realiza los siguientes pasos:\n",
        "   - Extrae los caracteres únicos del texto y los almacena en la variable `chars`.\n",
        "   - Genera el diccionario `int2char`, que mapea índices a caracteres.\n",
        "   - Genera el diccionario `char2int`, que mapea caracteres a índices.\n",
        "   - Codifica el texto completo como una secuencia de enteros utilizando el diccionario `char2int`.\n",
        "\n",
        "\n",
        "### 5. **Exportación de Datos**\n",
        "   - Después de realizar el preprocesamiento, se exportan los caracteres únicos, los diccionarios de mapeo y el texto codificado para su uso posterior en el entrenamiento del modelo LSTM.\n",
        "   - Los datos se guardan en archivos `.pkl` (pickle)\n",
        "\n",
        "### 6. **Resultado Final**\n",
        "   - **`chars60.pkl`**: Un archivo que contiene el conjunto de caracteres únicos extraídos del texto.\n",
        "   - **`char2int60.pkl`**: Un diccionario que mapea cada carácter a un número entero.\n",
        "   - **`int2char60.pkl`**: Un diccionario que mapea números enteros a caracteres.\n",
        "   - **`encoded60.pkl`**: El texto completo codificado como una secuencia de enteros.\n",
        "\n",
        "## Conclusión\n",
        "\n",
        "Este notebook convierte un conjunto de historias para niños en un formato que puede ser utilizado por un modelo LSTM. El texto se convierte en una serie de números enteros y se crean diccionarios para ayudar a entrenar el modelo de manera más sencilla. Los datos procesados se guardan en archivos pickle para usarlos en futuras sesiones de entrenamiento.\n"
      ],
      "metadata": {
        "id": "dazczv7YBF6S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aRYmBE8XBFb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g8rJpP4NU6iy"
      },
      "outputs": [],
      "source": [
        "# Importar las librerías necesarias\n",
        "import numpy as np\n",
        "import base64\n",
        "import requests\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento del texto: convertir el corpus a caracteres únicos y mapearlos a índices\n",
        "def preprocess_text(text):\n",
        "    chars = tuple(set(text))\n",
        "    int2char = dict(enumerate(chars))\n",
        "    char2int = {ch: ii for ii, ch in int2char.items()}\n",
        "    encoded = np.array([char2int[ch] for ch in text])\n",
        "    return chars, int2char, char2int, encoded"
      ],
      "metadata": {
        "id": "OL-sZpdCVgUz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/cleaned_merged_fairy_tales_without_eos.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jOmEGy1GZHiI",
        "outputId": "7e1da845-1dd2-4d8a-ae3d-d5ce2b3af50e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-27 19:41:25--  https://raw.githubusercontent.com/adrianaleticiamartinez/mcd_deep_learning/refs/heads/main/cleaned_merged_fairy_tales_without_eos.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20635335 (20M) [text/plain]\n",
            "Saving to: ‘cleaned_merged_fairy_tales_without_eos.txt’\n",
            "\n",
            "cleaned_merged_fair 100%[===================>]  19.68M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-09-27 19:41:26 (346 MB/s) - ‘cleaned_merged_fairy_tales_without_eos.txt’ saved [20635335/20635335]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el dataset y preprocesarlo\n",
        "\n",
        "\n",
        "with open('cleaned_merged_fairy_tales_without_eos.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "chars, int2char, char2int, encoded = preprocess_text(text)"
      ],
      "metadata": {
        "id": "mDX_haahWGdC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Exportar `chars`\n",
        "with open('chars60.pkl', 'wb') as f:\n",
        "    pickle.dump(chars, f)\n",
        "\n",
        "# Exportar los diccionarios de mapeo\n",
        "with open('char2int60.pkl', 'wb') as f:\n",
        "    pickle.dump(char2int, f)\n",
        "\n",
        "with open('int2char60.pkl', 'wb') as f:\n",
        "    pickle.dump(int2char, f)"
      ],
      "metadata": {
        "id": "QVfKQg7LHhMn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('encoded60.pkl', 'wb') as f:\n",
        "    pickle.dump(encoded, f)"
      ],
      "metadata": {
        "id": "gCkaTSaDzfbe"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}